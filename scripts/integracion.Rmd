---
title: "Integración"
author: "Pamela Pairo"
date: "1/12/2021"
output: rmdformats::readthedown
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```


# Objetivo

Se utiliza en dataset de las ventas de asientos para bebes en automóviles. Se quiere predecir aquellos establecimientos que tienen una venta altas de dichos coches (High)

```{r}
library(tidyverse)
library(tidymodels)
library(workflows)
library(ISLR) #el dataset se encuentra en esta librería 
library(rpart.plot)

data(Carseats)

glimpse(Carseats)
```

```{r}
Carseats <- as_tibble(Carseats) %>%
  mutate(High = factor(if_else(Sales <= 10, "No", "Yes")))

Carseats$Sales <-NULL
```

```{r}
Carseats$High <- relevel(Carseats$High, ref = "Yes")
levels(Carseats$High)
```

# Análisis exploratorio

```{r}
boxplot(Carseats$Price)
```

¿Hay alguna variación en el precio respecto a si el local se localiza en una zona urbana o rural?

```{r}
boxplot(Price~Urban,
data=Carseats,
xlab="Urban",
ylab="Price",
col="orange",
border="brown"
)
```

¿Hay alguna relación entre la cantidad de ventas (variable High) y el precio de los asientos para autos para bebés?

```{r}
boxplot(Price~High,
data=Carseats,
xlab="High",
ylab="Price",
col="orange",
border="brown"
)
```

¿Cómo es la distribución del promedio de edades de la población local de los establecimientos que venden los asientos para bebes?

```{r}
qplot(Carseats$Age,
      geom="histogram",
      binwidth = 5,  
      main = "Histograma para la EDAD (Age)", 
      xlab = "Age",  
      fill=I("blue"), 
      col=I("red"), 
      alpha=I(.2),
      xlim=c(20,85))
```

```{r}
library(ggcorrplot)

numericals <- select_if(Carseats, is.numeric) 

### Correlation Matrix
cormat <- round(x = cor(numericals), digits = 2)
ggcorrplot::ggcorrplot(cor(numericals))
```

¿Hay desbalance en la variable respuesta?

```{r}
g <- ggplot(Carseats, aes(High))
g + geom_bar()
```


## División del dataset: Entrenamiento y testeo


```{r}
set.seed(123)#setear la semilla

# Create data split for train and test
df_split <- initial_split(Carseats,
                          prop = 0.8,
                          strata = High)

# Create training data
df_train <- df_split %>%
              training()

# Create testing data
df_test <- df_split %>%
              testing()

# Number of rows in train and test dataset
paste0("Total del dataset de entrenamiento: ", nrow(df_train))
paste0("Total del dataset de testeo: ", nrow(df_test))
```

# Preprocesamiento de datos usando `recipe`

```{r}
library(themis)

recipe_df <-  recipe (High~ ., data= df_train) %>% 
              step_corr(all_numeric_predictors()) %>% 
              step_scale(all_numeric_predictors())%>%
              step_dummy(all_nominal_predictors(), -all_outcomes()) %>% 
              step_upsample(High) %>% 
              prep()
              

```

## Cross-validation

```{r}
set.seed(1234)

fold_df <- vfold_cv(df_train, v=3)
fold_df$splits

```
# Especificando el modelo y tuneo de hiperparámetros

Recordemos:

1- Especificar el modelo (eg. Regresión logística, Random Forest, SVM, etc)

2- Con `set_engine()` se especifíca la familia de modelos

3- Con `set_mode()` se especifica el tipo de modelo a entrenarse (regresión o clasificación)

4- Usar la función `fit ()` para entrenar el modelo y, dentro de eso, debe proporcionar la notación de la fórmula y el conjunto de datos

Con `tune`, se especifica qué hiperparámetros van a ser tuneados.

```{r}
#Arboles de decisión
set.seed(234)
model_TREE <- decision_tree(tree_depth = tune(),  min_n = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

```

## Uniendo todo en un _Workflow_

```{r}
wf_TREE <- workflow() %>% 
          add_recipe(recipe_df) %>% 
          add_model(model_TREE)
       
```

Hiperparámetros

```{r}
param_grid <- grid_regular(tree_depth(), min_n(), levels = 3)
param_grid
```

## Entrenamiento

```{r}
doParallel::registerDoParallel() #paralelizamos los cálculos
set.seed(345)

tune_DF <- tune_grid(
  model_TREE,
  High~ .,
  resamples = fold_df, 
  grid = param_grid, 
  metrics = metric_set(accuracy, sensitivity, precision)
)

tune_DF
```

Las métricas provienen del rendimiento de la validación cruzada a través de los diferentes valores de los parámetros.

```{r}
collect_metrics(tune_DF)
```

```{r}
autoplot(tune_DF)
```

## Selección del mejor modelo

```{r}
param_final <- tune_DF %>%
  select_best(metric = "precision")
param_final
```


```{r}
wf_TREE <- wf_TREE %>%
  finalize_workflow(param_final)
```

```{r}
tree_final_fit <- fit(wf_TREE, data= df_train)
tree_final_fit
```

```{r}
tree_final_fit %>% extract_fit_engine() %>%
  rpart.plot()
```

# Evaluación en test

```{r}
rf_fit <- wf_TREE %>%
  # fit on the training set and evaluate on test set
  last_fit(df_split)

rf_fit
```

```{r}
test_performance <- rf_fit %>% collect_metrics()
test_performance
```

```{r}
# generate predictions from the test set
test_predictions <- rf_fit %>% collect_predictions()
test_predictions
```

## Matriz de confusion

```{r}
collect_predictions(rf_fit) %>%
  conf_mat(High, .pred_class)
```

```{r}
collect_predictions(rf_fit) %>%
  precision(High, .pred_class)
```

## Importancia de las variables

```{r}
library(vip)

final <- decision_tree(tree_depth = 8, min_n = 40) %>%
  set_engine("rpart") %>%
  set_mode("classification")

final_fit <- fit(final, High ~ ., data = df_train)
vip(final_fit)
```

