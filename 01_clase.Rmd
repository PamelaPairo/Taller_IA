---
output:
   xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    seal: false
    self_contained: true
    nature:
      highlightStyle: github
      highlightLines: false
      countIncrementalSlides: false
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---

class: title-slide, center, middle
background-image: url(images/portada.jpg)
background-size: cover

#Clase 1: Aprendizaje Supervisado
### Pamela E. Pairo

```{r setup, include = FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE)

library(knitr)
library(tidyverse)
# set default options
opts_chunk$set(echo=FALSE,
               collapse = TRUE,
               fig.width = 7.252,
               fig.height = 4,
               dpi = 300)
xaringanExtra::use_tile_view()
xaringanExtra::use_scribble(pen_size = 2)
xaringanExtra::use_clipboard()
xaringanExtra::use_webcam(width = 210, height = 220)
xaringanExtra::use_share_again()
xaringanExtra::use_tachyons()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)
xaringanExtra::use_panelset()
```

```{r xaringan-extra-styles, include=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```


```{r include=FALSE}
library(countdown)
```

```{r xaringan-logo, echo=FALSE}

xaringanExtra::use_fit_screen()
xaringanExtra::use_logo(
  image_url = "images/uade.jpg"
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("PT Sans", "300", "300i"),
  code_font_google   = google_font("Fira Mono")

)
```

---
class: inverse

## Hoja de Ruta

- Clase 1: Conceptos importantes. Clasificaci贸n vs. Regresi贸n. An谩lisis exploratorio y curaci贸n. Ingenier铆a de features. Sobreajuste. Trade off Sesgo-Varianza. Entrenamiento, evaluaci贸n y testeo. Regresi贸n lineal y polinomial. Ejercitaci贸n

- Clase 2: rboles de decisi贸n.Random Forest. SVM. Regresi贸n Log铆stica. Na茂ve Bayes. Hiperpar谩metros. M茅tricas. Ejercitaci贸n

- Clase 3: Validaci贸n cruzada. Redes neuronales. Selecci贸n de modelos. Ejercitaci贸n.

- Clase 4: Clustering. K-means. PCA. Embeddings. Ejercitaci贸n

- Clase 5: Consideraciones finales. Desbalanceo de clases. Problemas multiclase. Consultas para el trabajo final.

- Clase 6: Presentaci贸n de los trabajos finales

---
## Conceptos Importantes `r emo::ji("bulb")`

--

* __Muestra, punto, observaci贸n, instancia__ se refiere a una unidad de an谩lisis.

--

* __Atributos, predictores, variables independientes o descriptores__ son los datos de entrada para la ecuaci贸n de predicci贸n.

--

* __Salida, variable dependiente, variable respuesta, clase, o "target"__ es la cantidad a ser predicha. 

--

* __Datos categ贸ricos, tambi茅n conocidos como nominales o atributos__ toman valores espec铆ficos que no tienen escala. Ejemplo: bueno/malo, rojo/azul, etc. 

--

* __Datos continuos__ son a base de escalas num茅ricas. El costo de un producto, la presi贸n sangu铆nea, etc.

---

## Tipos de Aprendizaje

- **Aprendizaje supervisado**: Datos de entrenamiento + salida esperada

- **Aprendizaje no supervisado**: Datos de entrenamiento (sin salida esperada)

- **Aprendizaje semi-supervisado**: Datos de entrenamiento + pocas salida esperadas

- **Aprendizaje auto-supervisado**: Datos de entrenamiento auto generados (tareas pretexto)

- **Aprendizaje por refuerzo**: "Recompensas" por secuencias de acciones

---
## Tipos de aprendizaje

.center[
<img src="images/ml.png" width="88%"/>
]

---

##Regresi贸n vs. Clasificaci贸n

.pull-left[Si $y$ $\epsilon$ $R^n$: Entonces es un problema de **regresi贸n**.
]
.pull-right[
<img src="images/regresion.png" width="70%"/>
]

--

.pull-left[Si $y$ es categ贸rica: Entonces es un problema de **clasificaci贸n**.
]

.pull-right[
<img src="images/clasification.png" width="70%"/>
]
---
class: middle, center

### Regresi贸n vs. Clasificaci贸n: Ejemplos

--

Eficiencia de combustible para autom贸viles

--

Predecir si clientes van a contratar un seguro

--

Predicci贸n de precios de casas seg煤n variables geogr谩ficas

--

Analisis de sentimientos de noticias financieras (negativo/positivo)

---

## Entrenamiento, validaci贸n y testeo


* __Set de entrenamiento__ son los datos utilizados para el modelado. 

* __Set de validaci贸n__  ajuste/elecci贸n de hiperpar谩metros

* __Set de testeo__ son los datos utilizados para medir el desempe帽o del modelo, entre un conjunto de candidatos. 


.center[
<img src="images/split_data.png" width="70%"/>
]

---

### Ciclo de un proyecto en ciencia de datos

.center[
<img src="images/ciclo_data.png" width="100%"/>
]

---

class: inverse, middle, center

#  `r emo::ji("hammer")`
#An谩lisis exploratorio de datos y Curaci贸n

---

## An谩lisis exploratorio de datos 

- Distribuci贸n de las variables

--

- Outliers o datos at铆picos

--
- Presencia de valores faltantes

--

- Desbalance de las clases o grupos en estudio

--

- An谩lisis de la correlaci贸n entre variables

---

# Curaci贸n de datos `r emo::ji("hammer")`

- Imputaci贸n de datos ruidosos, faltantes o err贸neos.

--

- Codificaci贸n de variables categ贸ricas.

--

- Transformaci贸n de variables.

--

- Ingenier铆a de outliers.

--

- Escalado de Features

--

- Discretizaci贸n de variables continuas (ej. edad)

---


##Base de datos del Proyecto Final

.panelset[
.panel[.panel-name[Dataset]

Base de datos p煤blica llamada "Health Insurance Cross Sell Prediction" extra铆da de [Kaggle](https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction?select=train.csv)


```{r panel-chunk, echo=FALSE}
library(kableExtra)

df <- read.csv("scripts/data/train.csv")

df %>%
head() %>%
  knitr::kable(format = "html")%>%
  kable_styling() %>%
  kableExtra::scroll_box(width = "100%")

```
]

.panel[.panel-name[Variables]

- **id**	煤nico ID para el cliente
- **Gender**	g茅nero del cliente
- **Age** Edad del cliente
- **Driving_License**	0 : Cliente no tiene Licencia de Conducir, 1 : Cliente tiene licencia de conducir
- **Previously_Insured**	1 : Cliente tiene seguro de auto, 0 : Cliente no tiene seguro de auto
- **Vehicle_Age**	Edad del veh铆culo
- **Vehicle_Damage**	1 : El cliente sufri贸 da帽os en su veh铆culo en el pasado 0 : El cliente NO sufri贸 da帽os en su veh铆culo en el pasado
- **Annual_Premium**	La cantidad que el cliente debe pagar como premium en el a帽o.
- **PolicySalesChannel**	C贸digo an贸nimo para el canal de acercamiento al cliente, es decir. Diferentes agentes, por correo, por tel茅fono, en persona, etc.
- **Vintage**	N煤mero de d铆as que el cliente ha estado asociado con la empresa
- **Response**	1 : Cliente est谩 interesado, 0 : Cliente no est谩 interesado

]

.panel[.panel-name[Variable Respuesta]

```{r, echo=TRUE, fig.height = 3}

library(ggplot2)
# Basic barplot
g <- ggplot(df, aes(Response))
g + geom_bar()

```

.panel[.panel-name[Age y Gender]

```{r, echo=FALSE, fig.height = 3}

tbl <- with(df, table(Response, Age))
ggplot(as.data.frame(tbl), aes(factor(Age), Freq, fill = Response)) +     
  geom_col()
    
```


]
]
]



---

class: inverse, middle, center

#`r emo::ji("computer")`
###Demo An谩lisis exploratorio y Curaci贸n


---
class: inverse, middle, center

#Aprendizaje Supervisado: Regresi贸n

---
class: inverse, middle, center

## Descanso

```{r}

countdown(minutes = 15, seconds = 0, font_size="7em", color_background = "white")

```

---

## Regresi贸n Lineal

Busca ajustar los datos de entrenamiento a mediante una funci贸n que sea un **hiperplano**.


.center[
$y = \theta_0 +\theta_1 x_1+ \theta_2 x_2...+ \theta_d x_d$ $$y = \sum_{j = 0}^{d} \theta_j x_j$$
]

--
.center[
<img src="images/lineal.jpg" width="45%"/>
]
---
## Regresi贸n Lineal: Funci贸n de Costo

Utilizaremos una funci贸n de costo (error cuadr谩tico) para medir el error en la predicci贸n de y mediante f(x). Se busca minimizar la suma del error cuadr谩tico

.center[
<img src="images/costo.png" width="90%"/>
]

---
## Regresi贸n Polinomial

Busca ajustar los datos de entrenamiento mediante una **funci贸n polinomial**:

.center[
$y (x, w) = w_0 +w_1 x_1+ w_2 x^2...+ w_m x^m$ $$y(x, w) = \sum_{j = 0}^{m} w_j x^j$$
]

--

.center[
<img src="images/lineal_pol.jpg" width="80%"/>
]

---
## Sobreajuste o overfitting

.center[
<img src="images/over.jpg" width="80%"/>
]
--
.center[
<img src="images/costo_over.jpg" width="60%"/>
]

---
## Sobreajuste o overfitting

.bg-washed-light-purple.b--light-purple.ba.bw2.br3.shadow-5.ph4.mt5[

El sobreajuste ocurre cuando la funci贸n de costo es realmente peque帽o, pero la generalizaci贸n del modelo no es confiable. Esto se debe a que el modelo aprende "demasiado" del conjunto de datos de entrenamiento. 

Tambi茅n se dice, que el modelo memoriza los datos de entrenamiento por eso no generalizar谩 bien frente a nuevos datos. Un modelo que sobreajusta, tiene una **alta varianza**

]

---

#Trade-off sesgo-varianza

.center[
<img src="images/sesgo.png" width="62%"/>
]
---
class: center, middle

# `r emo::ji("bulb")`Tener siempre presente `r emo::ji("bulb")`

### El objetivo de un modelo de Machine Learning es que generalice bien frente a nuevos datos o datos no vistos por el modelo (set de testeo)

---

class: inverse, middle, center

#`r emo::ji("computer")`
###Demo Regresi贸n lineal y polinomial

---

## Comunidades y Recursos 煤tiles

.pull-left[
<img src="images/cheet_ggplot2.png" width="90%"/>
]

.pull-right[

<img src="images/r4data.png" width="50%"/>

]

.pull-left[

<img src="images/rladies.png" width="40%"/>
]

.pull-right[

<img src="images/stack.jpg" width="60%"/>
]

---

## Comunidades y Recursos 煤tiles

.pull-left[
<img src="images/comunidades_latin.png" width="100%"/>
]

--

.pull-right[

[10-12 de noviembre LatinR, VIRTUAL](https://latin-r.com/) Talleres y presentaciones orales.

<img src="images/latinr.jpg" width="90%"/>
]

---

##Referencias

- [Art铆culo acerca del Sobreajuste](https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690) en Towards to Data Science

- [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/DT.html) de Bradley Boehmke y Brandon Greenwell.

- [Tidy Modeling with R](https://www.tmwr.org/index.html) de Max Kuhn y Julia Silge

- [Introducci贸n a Machine Learning con Tidymodels](https://ml-tidy-wibds.netlify.app/material/), workshop dictado en el marco de Women in Bioinformatics & Data Science LA 2021

- [Supervised Machine Learning course](https://supervised-ml-course.netlify.app/) de Julia Silge