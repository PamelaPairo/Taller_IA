---
output:
   xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    seal: false
    self_contained: true
    nature:
      highlightStyle: github
      highlightLines: false
      countIncrementalSlides: false
---

class: title-slide, center, middle
background-image: url(images/portada.jpg)
background-size: cover

#Clase 6: Repaso
### Pamela E. Pairo

```{r setup, include = FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
library(tidyverse)
# set default options
opts_chunk$set(echo=FALSE,
               collapse = TRUE,
               fig.width = 7.252,
               fig.height = 4,
               dpi = 300)
xaringanExtra::use_tile_view()
xaringanExtra::use_clipboard()
xaringanExtra::use_scribble(pen_size = 2)
xaringanExtra::use_webcam(width = 210, height = 220)
xaringanExtra::use_share_again()
xaringanExtra::use_tachyons()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)
xaringanExtra::use_panelset()
```

```{r xaringan-extra-styles, include=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```


```{r xaringan-logo, echo=FALSE}

xaringanExtra::use_fit_screen()
xaringanExtra::use_logo(
  image_url = "images/uade.jpg"
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Open Sans", "400", "300i"),
  code_font_google   = google_font("Fira Mono")

)

colors = c(
  red = "#f34213",
  purple = "#3e2f5b",
  orange = "#ff8811",
  green = "#136f63",
  white = "#FFFFFF"
)
```

---

class: inverse

## Hoja de Ruta

- Clase 1: Conceptos importantes. Clasificaci贸n vs. Regresi贸n. An谩lisis exploratorio y curaci贸n. Ingenier铆a de features. Sobreajuste. Trade off Sesgo-Varianza. Entrenamiento, evaluaci贸n y testeo. Regresi贸n lineal y polinomial. Ejercitaci贸n

- Clase 2: rboles de decisi贸n.Random Forest. SVM. Regresi贸n Log铆stica. Na茂ve Bayes. Hiperpar谩metros. Ejercitaci贸n

- Clase 3: Validaci贸n cruzada. M茅tricas. Selecci贸n de modelos. Ejercitaci贸n.

- Clase 4: Clustering. K-means. PCA. Embeddings. Ejercitaci贸n

- Clase 5: Consideraciones finales. Desbalanceo de clases. Problemas multiclase. Consultas para el trabajo final.

---
## Tipos de aprendizaje

.center[
<img src="images/ml.png" width="88%"/>
]

---
### Ciclo de un proyecto en ciencia de datos

.center[
<img src="images/ciclo_data.png" width="100%"/>
]

---
class: inverse, middle, center

# 1. Definir el problema/objetivo

---
### Definir el Objetivo

驴Qu茅 variable se quiere predecir? 
驴De qu茅 datos se dispone o se requiere conseguir mas datos?  

###Regresi贸n vs. Clasificaci贸n

.pull-left[**.purple[Regresi贸n]**
]

.pull-right[
**.purple[Clasificaci贸n]**
]

.pull-left[

<img src="images/regresion.png" width="100%"/>
]

.pull-right[
<img src="images/clasification.png" width="100%"/>
]

---
class: inverse, middle, center

#  `r emo::ji("hammer")`
# 2. An谩lisis exploratorio de datos y Curaci贸n

---
## La importancia de conocer la base de datos

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[

驴Qu茅 variables est谩n disponibles?
驴Qu茅 distribuci贸n tienen?
驴C贸mo se relacionan las distintas variables?

]

- Distribuci贸n de las variables (Normal, $\chi^2$, binomial, etc)

- Outliers o datos at铆picos (boxplots, diagrama de viol铆n, evaluar residuos)

- Presencia de valores faltantes (evaluar la distribuci贸n de los NAs)

- Desbalance de las clases o grupos en estudio

- An谩lisis de la correlaci贸n entre variables (ej. matriz de correlaci贸n)

---
class: inverse, middle, center

# 3. Ingenier铆a de features

---

#Ingenier铆a de features

.pull-left[

- Imputaci贸n de datos ruidosos, faltantes o err贸neos.
- Codificaci贸n de variables categ贸ricas.
- Transformaci贸n de variables.
- Ingenier铆a de outliers.
- Escalado de Features
- Discretizaci贸n de variables continuas

]

.pull-right[

<img src="images/recipe.png" width="50%"/>
]



```{r, echo=TRUE, warning = FALSE}
library(tidymodels)

rec <-recipe (Response ~ ., data= df_train) %>% 
              step_scale(all_numeric_predictors(), -all_outcomes())%>%
              step_dummy(all_nominal_predictors()) %>% 
              prep()
```

---
class: inverse, middle, center

# 3. Modelado Predictivo

---
# Algoritmos vistos

.pull-left[
### Aprendizaje Supervisado

- Regresi贸n Lineal y polinomial
- rboles de decisi贸n
- Random Forest
- Support Vector Machine (SVM)
- Regresi贸n Log铆stica
- Na茂ve Bayes

.center[<img src="images/parsnip.png" width="45%"/>]
]

--

.pull-right[

###Aprendizaje No Supervisado

- K-means
- PCA
- TSNE

```{r, echo=TRUE, warning = FALSE}
library(Rtsne) #Tsne
library(factoextra)#PCA

```
]
---

## Conjuntos de validaci贸n y testeo

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt3[
El objetivo de un modelo de Machine Learning es que generalice bien frente a nuevos datos o datos no vistos por el modelo (set de testeo)
]

.center[<img src="images/dataset.png" width="48%"/>]

**.orange[Conjunto de validaci贸n]** nos sirve para hacer el tuneo de **.orange[hiperpar谩metros]** y la selecci贸n de modelos.

**.orange[Conjunto de testeo]** se utiliza para medir la performance del modelo mediante **.orange[m茅tricas]**

.right[
Imagen extra铆da de [aqu铆](https://www.machinecurve.com/index.php/2020/11/16/how-to-easily-create-a-train-test-split-for-your-machine-learning-model/#train-test-split-for-a-multilabel-dataset)
]

---
#M茅tricas

.pull-left[

###Regresi贸n

- Mean Square Error (MSE)

- Root Mean Square Error (RMSE)

- Mean Absolute Error (MAE)

.center[<img src="images/yardstick.png" width="45%"/>]
]

.pull-right[

###Clasificaci贸n

- Matriz de Confusi贸n

- Accuracy

- Precision

- Recall

- F1

- Curvas ROC y AUC
]