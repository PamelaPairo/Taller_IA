---
output:
   xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    seal: false
    self_contained: true
    nature:
      highlightStyle: github
      highlightLines: false
      countIncrementalSlides: false
---

class: title-slide, center, middle
background-image: url(images/portada.jpg)
background-size: cover

#Clase 5: Desbalance de datos
### Pamela E. Pairo

```{r setup, include = FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
library(tidyverse)
# set default options
opts_chunk$set(echo=FALSE,
               collapse = TRUE,
               fig.width = 7.252,
               fig.height = 4,
               dpi = 300)
xaringanExtra::use_tile_view()
xaringanExtra::use_clipboard()
xaringanExtra::use_scribble(pen_size = 2)
xaringanExtra::use_webcam(width = 210, height = 220)
xaringanExtra::use_share_again()
xaringanExtra::use_tachyons()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)
xaringanExtra::use_panelset()
```

```{r xaringan-extra-styles, include=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```


```{r xaringan-logo, echo=FALSE}

xaringanExtra::use_fit_screen()
xaringanExtra::use_logo(
  image_url = "images/uade.jpg"
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Open Sans", "400", "300i"),
  code_font_google   = google_font("Fira Mono")

)

colors = c(
  red = "#f34213",
  purple = "#3e2f5b",
  orange = "#ff8811",
  green = "#136f63",
  white = "#FFFFFF"
)
```

---

class: middle, center
# En la clase de hoy...

--

### En la primera parte:

Desbalance de clases en problemas de clasificaci√≥n

Consignas Trabajo Final
--

### **.orange[Recreo]** `r emo::ji("coffee")`üßâ

--

Pr√°ctica en R.

---

## ¬øQu√© es el desbalance de clases?

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[
Es un problema recurrente del aprendizaje supervisado en el que una clase supera en gran medida a otra clase. Este problema se enfrenta con m√°s frecuencia en problemas de clasificaci√≥n binaria que en problemas de clasificaci√≥n multiclase

El t√©rmino .purple[desbalance] se refiere a la disparidad encontrada en la variable dependiente (respuesta).
]

---
# Algunos Ejemplos

- Las transacciones fraudulentas en un banco.

- Detecci√≥n de un tipo de c√°ncer en los residentes de un √°rea elegida.

- Predecir si los mails son spams o no.

.pull-left[
<img src="images/fraude.jpg" width="85%"/>
]

.pull-right[
<img src="images/spam.jpg" width="100%"/>
]

---

class: middle, center

# Algunas formas de lidiar con el desbalance

`r emo::ji("heavy_check_mark")` Cambiar la m√©trica de evaluaci√≥n

--

`r emo::ji("heavy_check_mark")` Cambiar el algoritmo

--

`r emo::ji("heavy_check_mark")` Sobremuestrear la clase minoritaria

--

`r emo::ji("heavy_check_mark")` Submuestrear la clase mayoritaria

--

`r emo::ji("heavy_check_mark")` Generaci√≥n de muestras sint√©ticas

---

# Cambiar la m√©trica de evaluaci√≥n

**.purple[Accuracy]** no es la m√©trica adecuada cuando se tiene un dataset desbalanceado.

En su lugar, es mejor utilizar m√©tricas que tengan m√°s en cuenta los datos de las clases minoritarias como son la f1, la sensitividad o la precisi√≥n.

- **.orange[Matriz de confusi√≥n]**

- **.orange[Precision]**: el n√∫mero de verdaderos positivos (TP) dividido por todas las predicciones positivas (TP+ FP). La baja precisi√≥n indica un alto n√∫mero de falsos positivos.

- **.orange[Recall o Sensibilidad]**: el n√∫mero de verdaderos positivos (TP) dividido por el n√∫mero de valores positivos en los datos de la prueba (TP+ FN). Se la denomina tambi√©n Tasa de verdaderos positivos. Valores bajos indican una gran cantidad de falsos negativos.

- **.orange[F1]**: el promedio ponderado de **.orange[Precision]** y **.orange[Recall]**

---
# Cambiar el algoritmo

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[
Es una buena pr√°ctica probar varios algoritmos en nuestro problema de clasificaci√≥n con desbalanceo de datos.
]

---

# Sobremuestrear la clase minoritaria

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[
El sobremuestreo se puede definir como agregar m√°s copias de la clase minoritaria. 

Puede ser una buena opci√≥n cuando no se tiene una gran cantidad de datos con los que trabajar.
]

---

# Submuestrear la clase mayoritaria

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[

El submuestreo se puede definir como eliminar algunas observaciones de la clase mayoritaria. 

Puede ser una buena opci√≥n cuando se tiene una cantidad grande de datos (ej. millones de datos). 

.orange[Desventaja] : se est√° eliminando informaci√≥n que puede ser valiosa. Esto podr√≠a dar lugar a un ajuste inadecuado y una mala generalizaci√≥n del conjunto de testeo.

]

---
# Generaci√≥n de muestras sint√©ticas

.bg-washed-light-purple.b--light-purple.ba.bw2.br2.shadow-5.ph3.mt2[

SMOTE or Synthetic Minority Oversampling Technique

SMOTE usa un algoritmo de vecinos m√°s cercanos (KNN) para generar datos nuevos y sint√©ticos que podemos usar para entrenar nuestro modelo.
Nuevamente, es importante generar las nuevas muestras solo en el conjunto de entrenamiento para garantizar que nuestro modelo se generalice bien a los datos invisibles.

]

---

#Tener en cuenta

- En `R`, necesitamos instalar el siguiente paquete

```
install.packages("themis")

library(tidymodels)
library(themis)

```
- Hacer el split de los datos **ANTES** de probar t√©cnicas de sobremuestreo submuestreo.

Si se hace lo contrario, puede ocurrir que los mismos datos est√©n presentes tanto en el conjunto de entrenamiento como en el conjunto de testeo, causando el _overfitting_ y la baja generalizaci√≥n del modelo.

---
# Referencias

- [Art√≠culo de Towards to Data Science](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)

- [Tratamiento de clases desbalanceadas](https://machinelearningparatodos.com/tratamiento-de-clases-desbalanceadas/)

- [Practical Guide to deal with Imbalanced Classification Problems in R](https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/)

- [Themis](https://themis.tidymodels.org/)